# LLM Paper Reading
This repo lists some interesting LLM related papers.  

## LLM Embedding
* [Fine-Tuning LLaMA for Multi-Stage Text Retrieval](https://arxiv.org/pdf/2310.08319.pdf)
  * Keywords: Dense Retriever(RepLLaMA), Pointwise Reranker(RankLLaMA), Contrastive loss, MS MARCO, BEIR
* [Improving Text Embeddings with Large Language Models](https://arxiv.org/pdf/2401.00368.pdf)
  * Keywords: Synthetic Data Generation, Mistral-7b, Contrastive loss, Multilingual Retrieval, BEIR, MTEB

## LLM Prompting


## LLM Inference


## LLM Architectures
* [Mixtral of Experts](https://arxiv.org/pdf/2401.04088.pdf)
  * Keywords:  Mixtral 8x7B, Sparse Mixture of Experts (SMoE)
* [Mistral 7B](https://arxiv.org/pdf/2310.06825.pdf)
  * Keywords:  Grouped-Query Attention (GQA), Sliding Window Attention (SWA), Rolling Buffer Cache, Pre-fill and Chunking
* [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/pdf/2307.09288.pdf)
  * Keywords: Grouped-Query Attention (GQA), Context Length 4k, 2.0T Tokens
* [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971.pdf)
  * Keywords: Pre-normalization, SwiGLU activation function, Rotary Positional Embeddings (RoPE), Context Length 2k, 1.0T Tokens


## LLM Agents

## LLM Alignment
* [RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback](https://arxiv.org/pdf/2309.00267.pdf)
  * Keywords: RL from AI Feedback (RLAIF), Generating AI labels, Self Improvement

## LLM Survey
* [A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models](https://arxiv.org/pdf/2401.01313.pdf)
  * Keywords: LLM Hallucination, RAG, Knowledge Retrieval, CoNLI, CoVe


## Blogs


